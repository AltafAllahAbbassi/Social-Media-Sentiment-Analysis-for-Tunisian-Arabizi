{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tunisian_sentiment_analysis_starter_notebook.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AltafAllahAbbassi/Social-Media-Sentiment-Analysis-for-Tunisian-Arabizi/blob/main/Tunisian_sentiment_analysis_starter_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8N_WcO-ldbkv"
      },
      "source": [
        "Dataset 70 000(+:38239,n:2466,-:29295)<br> \n",
        "XGBoost  67%<br>\n",
        "Random Forest 75%<br>\n",
        "SVM 79%<br>\n",
        "Logistic Regression 78%<br>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dflmqI7EElzi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adaafdbb-44db-421e-8832-119f2d5db73f"
      },
      "source": [
        "!pip install texthero"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting texthero\n",
            "  Downloading https://files.pythonhosted.org/packages/48/82/643a2ecd63884fa174ab2d8b5d7422d09b2c71450f11e5cfe32b928b97ef/texthero-1.1.0-py3-none-any.whl\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.7/dist-packages (from texthero) (0.22.2.post1)\n",
            "Requirement already satisfied: tqdm>=4.3 in /usr/local/lib/python3.7/dist-packages (from texthero) (4.41.1)\n",
            "Requirement already satisfied: wordcloud>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from texthero) (1.5.0)\n",
            "Collecting unidecode>=1.1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/25/723487ca2a52ebcee88a34d7d1f5a4b80b793f179ee0f62d5371938dfa01/Unidecode-1.2.0-py2.py3-none-any.whl (241kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 23.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from texthero) (3.2.2)\n",
            "Requirement already satisfied: spacy<3.0.0 in /usr/local/lib/python3.7/dist-packages (from texthero) (2.2.4)\n",
            "Collecting nltk>=3.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/37/9532ddd4b1bbb619333d5708aaad9bf1742f051a664c3c6fa6632a105fd8/nltk-3.6.2-py3-none-any.whl (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 64.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from texthero) (1.1.5)\n",
            "Requirement already satisfied: plotly>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from texthero) (4.4.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from texthero) (1.19.5)\n",
            "Requirement already satisfied: gensim<4.0,>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from texthero) (3.6.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22->texthero) (1.0.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22->texthero) (1.4.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from wordcloud>=1.5.0->texthero) (7.1.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1.0->texthero) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1.0->texthero) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1.0->texthero) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1.0->texthero) (0.10.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0->texthero) (2.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0->texthero) (57.0.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0->texthero) (3.0.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0->texthero) (1.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0->texthero) (0.4.1)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0->texthero) (1.0.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0->texthero) (1.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0->texthero) (7.4.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0->texthero) (1.1.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0->texthero) (2.23.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0->texthero) (0.8.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from nltk>=3.3->texthero) (2019.12.20)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk>=3.3->texthero) (7.1.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.2->texthero) (2018.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from plotly>=4.2.0->texthero) (1.15.0)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from plotly>=4.2.0->texthero) (1.3.3)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim<4.0,>=3.6.0->texthero) (5.1.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<3.0.0->texthero) (4.6.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0->texthero) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0->texthero) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0->texthero) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0->texthero) (1.24.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<3.0.0->texthero) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<3.0.0->texthero) (3.4.1)\n",
            "Installing collected packages: unidecode, nltk, texthero\n",
            "  Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "Successfully installed nltk-3.6.2 texthero-1.1.0 unidecode-1.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJjzLUBRQfI2"
      },
      "source": [
        "# Handling datasets \n",
        "import pandas as pd\n",
        "\n",
        "# Some encoding and preprocessing textual data\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import texthero\n",
        "from texthero import preprocessing\n",
        "\n",
        "# Set of ML classifiers to be used\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import svm\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7N_FxroQimt"
      },
      "source": [
        "def preprocess(data):\n",
        "    data = data.copy()\n",
        "    #removing diacritics\n",
        "    data['text'] = preprocessing.remove_diacritics(data['text'])\n",
        "    return data"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4ave48oQqcz"
      },
      "source": [
        "# Read the training and testing datasets\n",
        "train_df = pd.read_csv('/content/drive/MyDrive/sentiment analysis tunisian dialect/Train.csv')\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/sentiment analysis tunisian dialect/Test.csv')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKVc3TDvjwxu",
        "outputId": "277b0776-145f-4e5f-bf5a-e384e17123ff"
      },
      "source": [
        "len(train_df+test_df)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "70000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SayIMblBQlv2"
      },
      "source": [
        "# Preprocessing\n",
        "train = preprocess(train_df)\n",
        "test = preprocess(test_df)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGnE37QDQn5k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b942352-db0e-49b1-f9b3-d9b819bd0f08"
      },
      "source": [
        "# Building a vextorizer object that allow us to transform the texts into a numerical representation (vector)\n",
        "# and fit it on the training pieces of texts\n",
        "vectorizer = TfidfVectorizer(ngram_range=(1, 3)).fit(train['text'].values)\n",
        "len(vectorizer.vocabulary_)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1087890"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldCzxMEnRTPy"
      },
      "source": [
        "# Split the training dataset into training and validation\n",
        "X_train, X_val, y_train, y_val = train_test_split(train, train['label'], test_size=0.2, random_state=0,stratify=train['label'])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWdAWFb-RwF2"
      },
      "source": [
        "# Transform training, validation and testing texts into vectors\n",
        "X_train = vectorizer.transform(X_train['text'].values)\n",
        "X_val = vectorizer.transform(X_val['text'].values)\n",
        "X_test = vectorizer.transform(test['text'].values)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6vfbgp1kCt3"
      },
      "source": [
        "Y = y_train.tolist() + y_val.tolist()\n",
        "pos = 0\n",
        "neg = 0\n",
        "neu = 0\n",
        "for y in Y:\n",
        "  if y==1:\n",
        "    pos = pos+1\n",
        "  elif y==0:\n",
        "    neu = neu+1\n",
        "  elif y==- 1:\n",
        "    neg = neg +1\n",
        "  else :\n",
        "    print(\"y\")"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vTxAeO9vlA1P",
        "outputId": "2705aa52-8165-4e0c-bbf4-acfe4dfbd5e9"
      },
      "source": [
        "print(\"pos\",pos)\n",
        "print(\"neg\",neg)\n",
        "print(\"neu\",neu)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pos 38239\n",
            "neg 29295\n",
            "neu 2466\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMtDh9fYdLWr"
      },
      "source": [
        "You can try to tweak the model's parameters in order to get better performances I used the default setting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8a9TNFR_cIOM"
      },
      "source": [
        "# Logistic Regression\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "he2T1QVp3_mG",
        "outputId": "8078d65a-149c-4239-e656-f3650d14b7e0"
      },
      "source": [
        "clf1 = LogisticRegression(random_state=0)\n",
        "model1 = clf1.fit(X_train, y_train)\n",
        "pred1 = model1.predict(X_val)\n",
        "print('accuracy %s' % accuracy_score(pred1, y_val))\n",
        "print(classification_report(y_val,pred1,digits=4))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.7850714285714285\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1     0.7357    0.8145    0.7731      5859\n",
            "           0     1.0000    0.0264    0.0514       493\n",
            "           1     0.8274    0.8115    0.8193      7648\n",
            "\n",
            "    accuracy                         0.7851     14000\n",
            "   macro avg     0.8544    0.5508    0.5479     14000\n",
            "weighted avg     0.7951    0.7851    0.7729     14000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMW5gdBidFTV"
      },
      "source": [
        "# SVM\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2tIKJyESefC",
        "outputId": "7c407f34-6395-4911-f856-fe7a1c2dc12f"
      },
      "source": [
        "# clf2 = svm.SVC(C=2)\n",
        "# model2 = clf2.fit(X_train, y_train)\n",
        "# pred2 = model2.predict(X_val)\n",
        "print('accuracy %s' % accuracy_score(pred2, y_val))\n",
        "print(classification_report(y_val,pred2,digits=4))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.7912857142857143\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1     0.7371    0.8307    0.7811      5859\n",
            "           0     0.9310    0.0548    0.1034       493\n",
            "           1     0.8393    0.8086    0.8237      7648\n",
            "\n",
            "    accuracy                         0.7913     14000\n",
            "   macro avg     0.8358    0.5647    0.5694     14000\n",
            "weighted avg     0.7998    0.7913    0.7805     14000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSs2ZXQ2dkdq"
      },
      "source": [
        "# Random Forest\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4bnHl2hgoip",
        "outputId": "3a38c039-0be0-494e-e512-51edb2be042a"
      },
      "source": [
        "clf3 = RandomForestClassifier()\n",
        "model3 = clf3.fit(X_train, y_train)\n",
        "pred3 = model3.predict(X_val)\n",
        "print('accuracy %s' % accuracy_score(pred3, y_val))\n",
        "print(classification_report(y_val,pred3,digits=4))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.7530714285714286\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1     0.7272    0.7257    0.7265      5859\n",
            "           0     0.7246    0.1014    0.1779       493\n",
            "           1     0.7720    0.8160    0.7934      7648\n",
            "\n",
            "    accuracy                         0.7531     14000\n",
            "   macro avg     0.7413    0.5477    0.5659     14000\n",
            "weighted avg     0.7516    0.7531    0.7437     14000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDZw2lpleDT7"
      },
      "source": [
        "# XGBoost\n",
        "\n",
        "https://xgboost.readthedocs.io/en/latest/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNjE57QN73rV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6371847e-2aa6-43a4-f5f1-276c71e2d0eb"
      },
      "source": [
        "clf4 = XGBClassifier()\n",
        "model4 = clf4.fit(X_train, y_train)\n",
        "pred4 = model4.predict(X_val)\n",
        "print('accuracy %s' % accuracy_score(pred4, y_val))\n",
        "print(classification_report(y_val,pred4,digits=4))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.6707142857142857\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1     0.7195    0.4554    0.5578      5859\n",
            "           0     0.7778    0.0284    0.0548       493\n",
            "           1     0.6529    0.8771    0.7486      7648\n",
            "\n",
            "    accuracy                         0.6707     14000\n",
            "   macro avg     0.7167    0.4536    0.4537     14000\n",
            "weighted avg     0.6852    0.6707    0.6443     14000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}